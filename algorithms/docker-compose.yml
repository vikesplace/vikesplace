volumes:
  certs:
    driver: local
  psqldata:
    driver: local
  esdata:
    driver: local
  kibanadata:
    driver: local
  logstashdata:
    driver: local
  metricbeatdata:
    driver: local
  mongodbdata:
    driver: local
  neo4jdata:
    driver: local
  kafkadata:
    driver: local
  zookeeperdata:
    driver: local
  mongo_key:
    driver: local
  pgsyncdata:
    driver: local
  redisdata:
    driver: local

networks:
  default:
    name: elastic
    external: false

services:
  postgresql:
    image: postgis/postgis:latest
    volumes:
      - ./postgresql:/docker-entrypoint-initdb.d
      - psqldata:/var/lib/postgresql/data
    restart: always
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    ports:
      - ${POSTGRES_PORT}:5432
    command: [ "postgres", "-c", "wal_level=logical" ]
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}" ]
      interval: 30s
      timeout: 10s
      retries: 5
  
  redis:
    image: redis:alpine
    volumes:
      - redisdata:/data
    command: redis-server --requirepass ${REDIS_PASSWORD}
    healthcheck:
      test: [ "CMD", "redis-cli", "--raw", "incr", "ping" ]
      interval: 30s
      timeout: 10s
      retries: 5

  pgsync:
    depends_on:
      postgresql:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
      redis:
        condition: service_healthy
    image: python:3.11-slim
    volumes:
      - ./pgsync:/usr/src/conf
      - pgsyncdata:/usr/src/app
      - certs:/usr/share/pgsync
    environment:
      - PG_USER=${POSTGRES_USER}
      - PG_HOST=postgresql
      - PG_PORT=${POSTGRES_PORT}
      - PG_PASSWORD=${POSTGRES_PASSWORD}
      - LOG_LEVEL=INFO
      - ELASTICSEARCH_PORT=${ES_PORT}
      - ELASTICSEARCH_SCHEME=https
      - ELASTICSEARCH_HOST=elasticsearch
      - ELASTICSEARCH_CA_CERTS=/usr/src/conf/ca.crt
      - ELASTICSEARCH_USER=${ES_USER}
      - ELASTICSEARCH_PASSWORD=${ELASTIC_PASSWORD}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_AUTH=${REDIS_PASSWORD}
      - PYTHONPATH=/usr/src/conf
    entrypoint: >
      sh -c "
      pip install -q --no-cache-dir --upgrade pip &&
      pip install -q --no-cache-dir pgsync &&
      cp /usr/share/pgsync/ca/ca.crt /usr/src/conf/ca.crt &&
      bootstrap --config /usr/src/conf/pgsync_schema.json &&
      pgsync --config /usr/src/conf/pgsync_schema.json --daemon
      "

  neo4j:
    build: 
      context: ./neo4j/conf
      dockerfile: Dockerfile
    container_name: neo4j
    environment:
      NEO4J_AUTH: ${NEO4J_AUTH}
      NEO4J_ACCEPT_LICENSE_AGREEMENT: "yes"
      #NEO4J_server_config_strict_validation_enabled: "false"
      NEO4J_apoc_initializer_cypher: 'CALL apoc.cypher.runSchemaFile("file:///var/lib/neo4j/init.cypher");'
      NEO4JLABS_PLUGINS: '["apoc"]' 
      NEO4J_apoc_export_file_enabled: "true" 
      NEO4J_apoc_import_file_enabled: "true" 
      NEO4J_apoc_import_file_use__neo4j__config: "true" 
      NEO4J_dbms_directories_import: "/"
      NEO4J_dbms.security.procedures.unrestricted: "apoc.*"
      NEO4J_dbms.security.procedures.allowlist: "apoc.*"
      NEO4JLABS_PLUGINS__ENABLED__PLUGIN__INSTALL: "false"
    ports:
      - 7474:7474
      - 7687:7687
    volumes:
      - neo4jdata:/data
      - ./neo4j/conf/init.sh:/docker-entrypoint-initdb.d/init.cypher
      - ./neo4j/conf/apoc.conf:/var/lib/apoc.conf
      - ./neo4j/conf/init.cypher:/var/lib/neo4j/init.cypher
    depends_on:
      - kafka
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--spider", "http://neo4j:7474"]
      #test: ["CMD-SHELL", "cypher-shell -u neo4j -p neo4j_$3ng499"]
      interval: 10s
      timeout: 10s
      retries: 10
  
  zookeeper:
    image: wurstmeister/zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeperdata:/data

  kafka:
    image: wurstmeister/kafka:2.12-2.2.1
    ports:
      - "9092:9092"
    environment:
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_CREATE_TOPICS: "users_topic:1:1,listings_topic:1:1,user.vikesplace.user_activity.activities:1:1"
    volumes:
      - kafkadata:/var/lib/kafka
      - /var/run/docker.sock:/var/run/docker.sock
    healthcheck:
      test: ["CMD", "nc", "-z", "kafka", "9092"]
      interval: 30s
      timeout: 10s
      retries: 5

  kafka-connect:
    build: 
      context: /kafka-connect
      dockerfile: Dockerfile
    ports:
      - "8083:8083"
    volumes:
      - kafkadata:/var/lib/kafka/data
    depends_on:
      - kafka
      - neo4j
    environment:
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}
      - NEO4J_USER=${NEO4J_USER}
      - CONNECT_BOOTSTRAP_SERVERS=kafka:9092 
      - CONNECT_REST_ADVERTISED_HOST_NAME=kafka-connect 
      - CONNECT_GROUP_ID=kafka-connect-group 
      - CONNECT_CONFIG_STORAGE_TOPIC=connect-configs 
      - CONNECT_OFFSET_STORAGE_TOPIC=connect-offsets 
      - CONNECT_STATUS_STORAGE_TOPIC=connect-status 
      - CONNECT_KEY_CONVERTER=org.apache.kafka.connect.json.JsonConverter 
      - CONNECT_VALUE_CONVERTER=org.apache.kafka.connect.json.JsonConverter 
      - CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE=false 
      - CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE=false 
      - CONNECT_PLUGIN_PATH=/usr/share/java/
      - CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR=1
      - CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR=1
      - CONNECT_STATUS_STORAGE_REPLICATION_FACTOR=1
    command: >
      bash -c "
        # Start Kafka Connect in the background
        /etc/confluent/docker/run &

        # Wait for Kafka Connect to be ready
        while ! nc -z localhost 8083; do
          echo 'Waiting for Kafka Connect to start...'
          sleep 5
        done

        #confluent-hub install --no-prompt mongodb/kafka-connect-mongodb:latest

        #Register the Neo4j sink connector if not already registered
        if ! curl -s http://localhost:8083/connectors | grep neo4j-sink; then
          echo 'Registering Neo4j sink connector...'
          curl -X POST -H 'Content-Type: application/json' --data @/etc/kafka-connect/neo4j-sink.json http://localhost:8083/connectors
        fi

        # Register the MongoDB source connector if not already registered
        if ! curl -s http://localhost:8083/connectors | grep mongo-source; then
          echo 'Registering MongoDB source connector...'
          curl -X POST -H 'Content-Type: application/json' --data @/etc/kafka-connect/mongo-source.json http://localhost:8083/connectors
        fi

        # Periodic synchronization every 5 minutes (300 seconds)
        while true; do
          echo 'Synchronizing connectors...'
          curl -X POST -H 'Content-Type: application/json' --data @/etc/kafka-connect/neo4j-sink.json http://localhost:8083/connectors
          curl -X POST -H 'Content-Type: application/json' --data @/etc/kafka-connect/mongo-source.json http://localhost:8083/connectors
          sleep 300
        done

        # Wait for Kafka Connect to terminate (forwarding signals)
        wait
      "
  
  neo4j-relations-kafka-connect:
    build: 
      context: /neo4j-relations-kafka-connect
      dockerfile: Dockerfile
    restart: always
    depends_on:
      - kafka
      - neo4j
    environment:
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}
      - NEO4J_USER=${NEO4J_USER}

  setup:
    image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
    volumes:
      - certs:/usr/share/elasticsearch/config/certs
    user: "0"
    command: >
      bash -c '
        if [ x${ELASTIC_PASSWORD} == x ]; then
          echo "Set the ELASTIC_PASSWORD environment variable in the .env file";
          exit 1;
        elif [ x${KIBANA_PASSWORD} == x ]; then
          echo "Set the KIBANA_PASSWORD environment variable in the .env file";
          exit 1;
        fi;
        if [ ! -f config/certs/ca.zip ]; then
          echo "Creating CA";
          bin/elasticsearch-certutil ca --silent --pem -out config/certs/ca.zip;
          unzip config/certs/ca.zip -d config/certs;
        fi;
        if [ ! -f config/certs/certs.zip ]; then
          echo "Creating certs";
          echo -ne \
          "instances:\n"\
          "  - name: elasticsearch\n"\
          "    dns:\n"\
          "      - elasticsearch\n"\
          "      - localhost\n"\
          "    ip:\n"\
          "      - 127.0.0.1\n"\
          "  - name: kibana\n"\
          "    dns:\n"\
          "      - kibana\n"\
          "      - localhost\n"\
          "    ip:\n"\
          "      - 127.0.0.1\n"\
          > config/certs/instances.yml;
          bin/elasticsearch-certutil cert --silent --pem -out config/certs/certs.zip --in config/certs/instances.yml --ca-cert config/certs/ca/ca.crt --ca-key config/certs/ca/ca.key;
          unzip config/certs/certs.zip -d config/certs;
        fi;
        echo "Setting file permissions"
        chown -R root:root config/certs;
        find . -type d -exec chmod 750 \{\} \;;
        find . -type f -exec chmod 640 \{\} \;;
        echo "Waiting for Elasticsearch availability";
        until curl -s --cacert config/certs/ca/ca.crt https://elasticsearch:9200 | grep -q "missing authentication credentials"; do sleep 30; done;
        echo "Setting kibana_system password";
        until curl -s -X POST --cacert config/certs/ca/ca.crt -u "elastic:${ELASTIC_PASSWORD}" -H "Content-Type: application/json" https://elasticsearch:9200/_security/user/kibana_system/_password -d "{\"password\":\"${KIBANA_PASSWORD}\"}" | grep -q "^{}"; do sleep 10; done;
        echo "All done!";
      '
    healthcheck:
      test: ["CMD-SHELL", "[ -f config/certs/elasticsearch/elasticsearch.crt ]"]
      interval: 1s
      timeout: 5s
      retries: 120

  elasticsearch:
    depends_on:
      setup:
        condition: service_healthy
    image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
    labels:
      co.elastic.logs/module: elasticsearch
    volumes:
      - certs:/usr/share/elasticsearch/config/certs
      - esdata:/usr/share/elasticsearch/data
    ports:
      - ${ES_PORT}:9200
    environment:
      - node.name=elasticsearch
      - cluster.name=${CLUSTER_NAME}
      - discovery.type=single-node
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - bootstrap.memory_lock=true
      - xpack.security.enabled=true
      - xpack.security.http.ssl.enabled=true
      - xpack.security.http.ssl.key=certs/elasticsearch/elasticsearch.key
      - xpack.security.http.ssl.certificate=certs/elasticsearch/elasticsearch.crt
      - xpack.security.http.ssl.certificate_authorities=certs/ca/ca.crt
      - xpack.security.transport.ssl.enabled=true
      - xpack.security.transport.ssl.key=certs/elasticsearch/elasticsearch.key
      - xpack.security.transport.ssl.certificate=certs/elasticsearch/elasticsearch.crt
      - xpack.security.transport.ssl.certificate_authorities=certs/ca/ca.crt
      - xpack.security.transport.ssl.verification_mode=certificate
      - xpack.license.self_generated.type=${LICENSE}
    mem_limit: ${ES_MEM_LIMIT}
    ulimits:
      memlock:
        soft: -1
        hard: -1
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s --cacert config/certs/ca/ca.crt https://localhost:9200 | grep -q 'missing authentication credentials'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120

  kibana:
    depends_on:
      elasticsearch:
        condition: service_healthy
    image: docker.elastic.co/kibana/kibana:${STACK_VERSION}
    labels:
      co.elastic.logs/module: kibana
    volumes:
      - certs:/usr/share/kibana/config/certs
      - kibanadata:/usr/share/kibana/data
    ports:
      - ${KIBANA_PORT}:5601
    environment:
      - SERVERNAME=kibana
      - ELASTICSEARCH_HOSTS=https://elasticsearch:9200
      - ELASTICSEARCH_USERNAME=kibana_system
      - ELASTICSEARCH_PASSWORD=${KIBANA_PASSWORD}
      - ELASTICSEARCH_SSL_CERTIFICATEAUTHORITIES=config/certs/ca/ca.crt
      - XPACK_SECURITY_ENCRYPTIONKEY=${ENCRYPTION_KEY}
      - XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY=${ENCRYPTION_KEY}
      - XPACK_REPORTING_ENCRYPTIONKEY=${ENCRYPTION_KEY}
    mem_limit: ${KB_MEM_LIMIT}
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s -I http://localhost:5601 | grep -q 'HTTP/1.1 302 Found'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120

  metricbeat:
    depends_on:
      elasticsearch:
        condition: service_healthy
      kibana:
        condition: service_healthy
    image: docker.elastic.co/beats/metricbeat:${STACK_VERSION}
    user: root
    volumes:
      - certs:/usr/share/metricbeat/certs
      - metricbeatdata:/usr/share/metricbeat/data
      - "./metricbeat.yml:/usr/share/metricbeat/metricbeat.yml:ro"
      - "/var/run/docker.sock:/var/run/docker.sock:ro"
      - "/sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro"
      - "/proc:/hostfs/proc:ro"
      - "/:/hostfs:ro"
    environment:
      - ELASTIC_USER=elastic
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - ELASTIC_HOSTS=https://elasticsearch:9200
      - KIBANA_HOSTS=http://kibana:5601
      - LOGSTASH_HOSTS=http://logstash:9600
    command:
      - --strict.perms=false

  logstash:
    depends_on:
      postgresql:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
      kibana:
        condition: service_healthy
      kafka:
        condition: service_healthy
    build:
      context: ./logstash
      dockerfile: Dockerfile
      args:
        - STACK_VERSION=${STACK_VERSION}
    labels:
      co.elastic.logs/module: logstash
    user: root
    volumes:
      - certs:/usr/share/logstash/certs
      - logstashdata:/usr/share/logstash/data
    environment:
      - xpack.monitoring.enabled=false
      - ELASTIC_USER=elastic
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - ELASTIC_HOSTS=https://elasticsearch:9200
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}

  mongodb:
    build:
       context: ./mongodb
       dockerfile: Dockerfile
    restart: always
    ports:
      - "27017:27017"
    volumes:
      - mongo_key:/etc/mongodb-keyfile
      - mongodbdata:/data/db
    environment:
      MONGO_INITDB_DATABASE: ${MONGO_INITDB_DATABASE}
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_INITDB_ROOT_USERNAME}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_INITDB_ROOT_PASSWORD}
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"] #echo "rs.status()" | mongosh --port 27017 --quiet
      interval: 5s
      timeout: 30s
      start_period: 0s
      start_interval: 1s
      retries: 30

  search:
    depends_on:
      postgresql:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
      kibana:
        condition: service_healthy
      mongodb:
        condition: service_healthy
    build: 
      context: ./search
    volumes:
      - certs:/usr/share/search
    ports:
      - "8000:8000"
    environment:
      - ES_HOST=elasticsearch
      - ES_PORT=${ES_PORT}
      - ES_USER=${ES_USER}
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - MONGO_HOST=mongodb
      - MONGO_PORT=${MONGO_PORT}
      - MONGO_INITDB_ROOT_USERNAME=${MONGO_INITDB_ROOT_USERNAME}
      - MONGO_INITDB_ROOT_PASSWORD=${MONGO_INITDB_ROOT_PASSWORD}
      - MONGO_INITDB_DATABASE=${MONGO_INITDB_DATABASE}
    entrypoint: 
      [
        "/bin/sh", "-c", 
        "/search/wait-for-cert.sh \
        && /search/wait-for-elastic.sh \
        && fastapi run routes.py --port 8000"
      ]
  
  recommender:
    depends_on:
      postgresql:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
      kibana:
        condition: service_healthy
      mongodb:
        condition: service_healthy
    build: 
      context: ./recommender
    volumes:
      - certs:/usr/share/recommender
    ports:
      - "8001:8001"
    environment:
      - ES_HOST=elasticsearch
      - ES_PORT=${ES_PORT}
      - ES_USER=${ES_USER}
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - MONGO_HOST=mongodb
      - MONGO_PORT=${MONGO_PORT}
      - MONGO_INITDB_ROOT_USERNAME=${MONGO_INITDB_ROOT_USERNAME}
      - MONGO_INITDB_ROOT_PASSWORD=${MONGO_INITDB_ROOT_PASSWORD}
      - MONGO_INITDB_DATABASE=${MONGO_INITDB_DATABASE}
    entrypoint: 
      [
        "/bin/sh", "-c", 
        "/recommender/wait-for-cert.sh \
        && /recommender/wait-for-elastic.sh \
        && fastapi run routes.py --port 8001"
      ]

  recommender_advanced:
    depends_on:
      neo4j:
        condition: service_healthy
    build: 
      context: ./recommender_advanced
      dockerfile: Dockerfile
    ports:
      - "8002:8002"
    environment:
      - NEO4J_USER=${NEO4J_USER}
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}
      - NEO4J_URI=${NEO4J_URI_DOCKER}
    entrypoint: 
      [
        "/bin/sh", "-c", 
        "fastapi run routes.py --port 8002"
      ]