volumes:
  certs:
    driver: local
  psqldata-vikesplace:
    driver: local
  esdata:
    driver: local
  kibanadata:
    driver: local
  logstashdata-elasticsearch:
    driver: local
  logstashdata-kafka:
    driver: local
  metricbeatdata:
    driver: local
  mongodbdata:
    driver: local
  neo4jdata:
    driver: local
  kafkadata:
    driver: local
  zookeeperdata:
    driver: local

networks:
  default:
    name: elastic
    external: false

services:
  postgresql:
    image: postgis/postgis:latest
    volumes:
      - ./postgresql:/docker-entrypoint-initdb.d
      - psqldata-vikesplace:/var/lib/postgresql/data
    restart: always
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    ports:
      - ${POSTGRES_PORT}:5432
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}" ]
      interval: 30s
      timeout: 10s
      retries: 5

  neo4j:
    image: neo4j:4.4.31-enterprise
    container_name: neo4j
    environment:
      NEO4J_AUTH: ${NEO4J_AUTH}
      NEO4J_ACCEPT_LICENSE_AGREEMENT: "yes"
      NEO4J_server_config_strict_validation_enabled: "false"
      NEO4J_apoc_initializer_cypher: 'CALL apoc.cypher.runSchemaFile("file:////var/lib/neo4j/init.cypher");'
      NEO4JLABS_PLUGINS: '["apoc"]' 
      NEO4J_apoc_export_file_enabled: "true" 
      NEO4J_apoc_import_file_enabled: "true" 
      NEO4J_apoc_import_file_use__neo4j__config: "true" 
      NEO4J_dbms_directories_import: "/" 
    ports:
      - 7474:7474
      - 7687:7687
    volumes:
      - neo4jdata:/data
      - ./neo4j/conf/init.sh:/docker-entrypoint-initdb.d/init.cypher
      #- ./neo4j/neo4j-streams-4.1.5.jar:/plugins
      #- ./neo4j/streams.conf:/var/lib/neo4j/streams.conf
      - ./neo4j/conf/apoc.conf:/var/lib/apoc.conf
      - ./neo4j/conf/init.cypher:/var/lib/neo4j/init.cypher
    depends_on:
      - kafka
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--spider", "http://neo4j:7474"]
      interval: 10s
      timeout: 10s
      retries: 10
  
  zookeeper:
    image: wurstmeister/zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeperdata:/data

  kafka:
    image: wurstmeister/kafka:2.12-2.2.1
    ports:
      - "9092:9092"
    environment:
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    volumes:
      - kafkadata:/var/lib/kafka
      - /var/run/docker.sock:/var/run/docker.sock
    healthcheck:
      test: ["CMD", "nc", "-z", "kafka", "9092"]
      interval: 30s
      timeout: 10s
      retries: 5

  create-topics:
    image: confluentinc/cp-kafka:7.2.1
    depends_on:
      kafka:
        condition: service_healthy
    entrypoint: ["/bin/sh", "-c"]
    command: >
      "kafka-topics --create --topic users_topic --bootstrap-server kafka:9092 --partitions 1 --replication-factor 1 &&
       kafka-topics --create --topic listings_topic --bootstrap-server kafka:9092 --partitions 1 --replication-factor 1"

  kafka-connect:
    image: confluentinc/cp-kafka-connect:latest
    ports:
      - "8083:8083"
    volumes:
      - kafkadata:/var/lib/kafka/data
      - ./kafka-connect/neo4j-sink.json:/etc/kafka-connect/neo4j-sink.json
      - ./kafka-connect/neo4j-connect/neo4j-kafka-connect-neo4j-5.0.5:/usr/share/java/neo4j-kafka-connect-neo4j-5.0.5
    depends_on:
      - kafka
      - neo4j
    environment:
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}
      - NEO4J_USER=${NEO4J_USER}
      - CONNECT_BOOTSTRAP_SERVERS=kafka:9092 
      - CONNECT_REST_ADVERTISED_HOST_NAME=kafka-connect 
      - CONNECT_GROUP_ID=kafka-connect-group 
      - CONNECT_CONFIG_STORAGE_TOPIC=connect-configs 
      - CONNECT_OFFSET_STORAGE_TOPIC=connect-offsets 
      - CONNECT_STATUS_STORAGE_TOPIC=connect-status 
      - CONNECT_KEY_CONVERTER=org.apache.kafka.connect.json.JsonConverter 
      - CONNECT_VALUE_CONVERTER=org.apache.kafka.connect.json.JsonConverter 
      - CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE=false 
      - CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE=false 
      - CONNECT_PLUGIN_PATH=/usr/share/java
      - CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR=1
      - CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR=1
      - CONNECT_STATUS_STORAGE_REPLICATION_FACTOR=1
    command: >
      bash -c "
        # Start Kafka Connect in the background
        /etc/confluent/docker/run &

        # Wait for Kafka Connect to be ready
        while ! nc -z localhost 8083; do
          echo 'Waiting for Kafka Connect to start...'
          sleep 5
        done

        # Register the Neo4j sink connector
        echo 'Registering Neo4j sink connector...'
        curl -X POST -H 'Content-Type: application/json' --data @/etc/kafka-connect/neo4j-sink.json http://localhost:8083/connectors

        # Periodic synchronization every 5 minutes (300 seconds)
        while true; do
          echo 'Synchronizing connectors...'
          curl -X POST -H 'Content-Type: application/json' --data @/etc/kafka-connect/neo4j-sink.json http://localhost:8083/connectors
          sleep 300
        done

        # Wait for Kafka Connect to terminate (forwarding signals)
        wait
      "

  setup:
    image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
    volumes:
      - certs:/usr/share/elasticsearch/config/certs
    user: "0"
    command: >
      bash -c '
        if [ x${ELASTIC_PASSWORD} == x ]; then
          echo "Set the ELASTIC_PASSWORD environment variable in the .env file";
          exit 1;
        elif [ x${KIBANA_PASSWORD} == x ]; then
          echo "Set the KIBANA_PASSWORD environment variable in the .env file";
          exit 1;
        fi;
        if [ ! -f config/certs/ca.zip ]; then
          echo "Creating CA";
          bin/elasticsearch-certutil ca --silent --pem -out config/certs/ca.zip;
          unzip config/certs/ca.zip -d config/certs;
        fi;
        if [ ! -f config/certs/certs.zip ]; then
          echo "Creating certs";
          echo -ne \
          "instances:\n"\
          "  - name: elasticsearch\n"\
          "    dns:\n"\
          "      - elasticsearch\n"\
          "      - localhost\n"\
          "    ip:\n"\
          "      - 127.0.0.1\n"\
          "  - name: kibana\n"\
          "    dns:\n"\
          "      - kibana\n"\
          "      - localhost\n"\
          "    ip:\n"\
          "      - 127.0.0.1\n"\
          > config/certs/instances.yml;
          bin/elasticsearch-certutil cert --silent --pem -out config/certs/certs.zip --in config/certs/instances.yml --ca-cert config/certs/ca/ca.crt --ca-key config/certs/ca/ca.key;
          unzip config/certs/certs.zip -d config/certs;
        fi;
        echo "Setting file permissions"
        chown -R root:root config/certs;
        find . -type d -exec chmod 750 \{\} \;;
        find . -type f -exec chmod 640 \{\} \;;
        echo "Waiting for Elasticsearch availability";
        until curl -s --cacert config/certs/ca/ca.crt https://elasticsearch:9200 | grep -q "missing authentication credentials"; do sleep 30; done;
        echo "Setting kibana_system password";
        until curl -s -X POST --cacert config/certs/ca/ca.crt -u "elastic:${ELASTIC_PASSWORD}" -H "Content-Type: application/json" https://elasticsearch:9200/_security/user/kibana_system/_password -d "{\"password\":\"${KIBANA_PASSWORD}\"}" | grep -q "^{}"; do sleep 10; done;
        echo "All done!";
      '
    healthcheck:
      test: ["CMD-SHELL", "[ -f config/certs/elasticsearch/elasticsearch.crt ]"]
      interval: 1s
      timeout: 5s
      retries: 120

  elasticsearch:
    depends_on:
      setup:
        condition: service_healthy
    image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
    labels:
      co.elastic.logs/module: elasticsearch
    volumes:
      - certs:/usr/share/elasticsearch/config/certs
      - esdata:/usr/share/elasticsearch/data
    ports:
      - ${ES_PORT}:9200
    environment:
      - node.name=elasticsearch
      - cluster.name=${CLUSTER_NAME}
      - discovery.type=single-node
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - bootstrap.memory_lock=true
      - xpack.security.enabled=true
      - xpack.security.http.ssl.enabled=true
      - xpack.security.http.ssl.key=certs/elasticsearch/elasticsearch.key
      - xpack.security.http.ssl.certificate=certs/elasticsearch/elasticsearch.crt
      - xpack.security.http.ssl.certificate_authorities=certs/ca/ca.crt
      - xpack.security.transport.ssl.enabled=true
      - xpack.security.transport.ssl.key=certs/elasticsearch/elasticsearch.key
      - xpack.security.transport.ssl.certificate=certs/elasticsearch/elasticsearch.crt
      - xpack.security.transport.ssl.certificate_authorities=certs/ca/ca.crt
      - xpack.security.transport.ssl.verification_mode=certificate
      - xpack.license.self_generated.type=${LICENSE}
    mem_limit: ${ES_MEM_LIMIT}
    ulimits:
      memlock:
        soft: -1
        hard: -1
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s --cacert config/certs/ca/ca.crt https://localhost:9200 | grep -q 'missing authentication credentials'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120

  kibana:
    depends_on:
      elasticsearch:
        condition: service_healthy
    image: docker.elastic.co/kibana/kibana:${STACK_VERSION}
    labels:
      co.elastic.logs/module: kibana
    volumes:
      - certs:/usr/share/kibana/config/certs
      - kibanadata:/usr/share/kibana/data
    ports:
      - ${KIBANA_PORT}:5601
    environment:
      - SERVERNAME=kibana
      - ELASTICSEARCH_HOSTS=https://elasticsearch:9200
      - ELASTICSEARCH_USERNAME=kibana_system
      - ELASTICSEARCH_PASSWORD=${KIBANA_PASSWORD}
      - ELASTICSEARCH_SSL_CERTIFICATEAUTHORITIES=config/certs/ca/ca.crt
      - XPACK_SECURITY_ENCRYPTIONKEY=${ENCRYPTION_KEY}
      - XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY=${ENCRYPTION_KEY}
      - XPACK_REPORTING_ENCRYPTIONKEY=${ENCRYPTION_KEY}
    mem_limit: ${KB_MEM_LIMIT}
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s -I http://localhost:5601 | grep -q 'HTTP/1.1 302 Found'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120

  metricbeat:
    depends_on:
      elasticsearch:
        condition: service_healthy
      kibana:
        condition: service_healthy
    image: docker.elastic.co/beats/metricbeat:${STACK_VERSION}
    user: root
    volumes:
      - certs:/usr/share/metricbeat/certs
      - metricbeatdata:/usr/share/metricbeat/data
      - "./metricbeat.yml:/usr/share/metricbeat/metricbeat.yml:ro"
      - "/var/run/docker.sock:/var/run/docker.sock:ro"
      - "/sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro"
      - "/proc:/hostfs/proc:ro"
      - "/:/hostfs:ro"
    environment:
      - ELASTIC_USER=elastic
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - ELASTIC_HOSTS=https://elasticsearch:9200
      - KIBANA_HOSTS=http://kibana:5601
      - LOGSTASH_HOSTS=http://logstash:9600
    command:
      - --strict.perms=false

  logstash-elasticsearch:
    depends_on:
      postgresql:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
      kibana:
        condition: service_healthy
    build:
      context: ./logstash/logstash-elasticsearch
      dockerfile: Dockerfile
      args:
        - STACK_VERSION=${STACK_VERSION}
    labels:
      co.elastic.logs/module: logstash
    user: root
    volumes:
      - certs:/usr/share/logstash/certs
      - logstashdata-elasticsearch:/usr/share/logstash/data
    environment:
      - xpack.monitoring.enabled=false
      - ELASTIC_USER=elastic
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - ELASTIC_HOSTS=https://elasticsearch:9200
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}

  logstash-kafka:
    depends_on:
      postgresql:
        condition: service_healthy
      kafka:
        condition: service_healthy
    build:
      context: ./logstash/logstash-kafka
      dockerfile: Dockerfile
      args:
        - STACK_VERSION=${STACK_VERSION}
    labels:
      co.elastic.logs/module: logstash
    user: root
    volumes:
      - logstashdata-kafka:/usr/share/logstash/data
    environment:
      - xpack.monitoring.enabled=false
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}

  mongodb:
    image: mongo:latest
    volumes:
      - mongodbdata:/data/db
      - ./mongodb/init-mongo.js:/docker-entrypoint-initdb.d/init-mongo.js:ro
    ports:
      - "27017:27017"
    environment:
      - MONGO_INITDB_ROOT_USERNAME=${MONGO_INITDB_ROOT_USERNAME}
      - MONGO_INITDB_ROOT_PASSWORD=${MONGO_INITDB_ROOT_PASSWORD}
      - MONGO_INITDB_DATABASE=${MONGO_INITDB_DATABASE}
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 20s

  search:
    depends_on:
      postgresql:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
      kibana:
        condition: service_healthy
      mongodb:
        condition: service_healthy
    build: 
      context: ./search
    volumes:
      - certs:/usr/share/search
    ports:
      - "8000:8000"
    environment:
      - ES_HOST=elasticsearch
      - ES_PORT=${ES_PORT}
      - ES_USER=${ES_USER}
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - MONGO_HOST=mongodb
      - MONGO_PORT=${MONGO_PORT}
      - MONGO_INITDB_ROOT_USERNAME=${MONGO_INITDB_ROOT_USERNAME}
      - MONGO_INITDB_ROOT_PASSWORD=${MONGO_INITDB_ROOT_PASSWORD}
      - MONGO_INITDB_DATABASE=${MONGO_INITDB_DATABASE}
    entrypoint: 
      [
        "/bin/sh", "-c", 
        "/search/wait-for-cert.sh \
        && /search/wait-for-elastic.sh \
        && fastapi run routes.py --port 8000"
      ]
  
  recommender:
    depends_on:
      postgresql:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
      kibana:
        condition: service_healthy
      mongodb:
        condition: service_healthy
    build: 
      context: ./recommender
    volumes:
      - certs:/usr/share/recommender
    ports:
      - "8001:8001"
    environment:
      - ES_HOST=elasticsearch
      - ES_PORT=${ES_PORT}
      - ES_USER=${ES_USER}
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - MONGO_HOST=mongodb
      - MONGO_PORT=${MONGO_PORT}
      - MONGO_INITDB_ROOT_USERNAME=${MONGO_INITDB_ROOT_USERNAME}
      - MONGO_INITDB_ROOT_PASSWORD=${MONGO_INITDB_ROOT_PASSWORD}
      - MONGO_INITDB_DATABASE=${MONGO_INITDB_DATABASE}
    entrypoint: 
      [
        "/bin/sh", "-c", 
        "/recommender/wait-for-cert.sh \
        && /recommender/wait-for-elastic.sh \
        && fastapi run routes.py --port 8001"
      ]