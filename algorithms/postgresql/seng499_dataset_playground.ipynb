{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install Dependencies"
      ],
      "metadata": {
        "id": "wrqHqPMW7ZO8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kY125xr1dEPL"
      },
      "outputs": [],
      "source": [
        "!pip -q install datasets\n",
        "!pip -q install unidecode\n",
        "!pip -q install pandas pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -qq https://github.com/amazon-science/esci-data/raw/main/shopping_queries_dataset/shopping_queries_dataset_examples.parquet\n",
        "# !wget https://github.com/amazon-science/esci-data/raw/main/shopping_queries_dataset/shopping_queries_dataset_products.parquet"
      ],
      "metadata": {
        "id": "lBXAl7WpUm-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "from unidecode import unidecode\n",
        "import csv\n",
        "import datetime\n",
        "\n",
        "datasets.logging.set_verbosity_error()"
      ],
      "metadata": {
        "id": "qcEU75_Gw2cX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple POC"
      ],
      "metadata": {
        "id": "U4uGE5uE7cEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.load_dataset(\n",
        "    \"McAuley-Lab/Amazon-Reviews-2023\",\n",
        "    f\"raw_meta_Electronics\",\n",
        "    split=\"full\",\n",
        "    trust_remote_code=True,\n",
        "    streaming=True\n",
        ")\n",
        "\n",
        "# dataset = dataset.shuffle(seed=42, buffer_size=1_000)\n",
        "dataset = dataset.take(10)\n",
        "\n",
        "for i, item in enumerate(dataset):\n",
        "    print(item)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gORH5EbQ99hN",
        "outputId": "eccbd9a0-9cdf-4363-b620-bdcbc0f387eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'main_category': 'All Electronics', 'title': 'FS-1051 FATSHARK TELEPORTER V3 HEADSET', 'average_rating': 3.5, 'rating_number': 6, 'features': [], 'description': ['Teleporter V3 The “Teleporter V3” kit sets a new level of value in the FPV world with Fat Shark renowned performance and quality. The fun of FPV is experienced firsthand through the large screen FPV headset with integrated NexwaveRF receiver technology while simultaneously recording onboard HD footage with the included “PilotHD” camera. The “Teleporter V3” kit comes complete with everything you need to step into the cockpit of your FPV vehicle. We’ve included our powerful 250mW 5.8Ghz transmitter, 25 degree FOV headset (largest QVGA display available), the brand new “PilotHD” camera with live AV out and all the cables, antennas and connectors needed.'], 'price': 'None', 'images': {'hi_res': [None], 'large': ['https://m.media-amazon.com/images/I/41qrX56lsYL._AC_.jpg'], 'thumb': ['https://m.media-amazon.com/images/I/41qrX56lsYL._AC_US40_.jpg'], 'variant': ['MAIN']}, 'videos': {'title': [], 'url': [], 'user_id': []}, 'store': 'Fat Shark', 'categories': ['Electronics', 'Television & Video', 'Video Glasses'], 'details': '{\"Date First Available\": \"August 2, 2014\", \"Manufacturer\": \"Fatshark\"}', 'parent_asin': 'B00MCW7G9M', 'bought_together': None, 'subtitle': None, 'author': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Write `query.csv`"
      ],
      "metadata": {
        "id": "vDYTlGkPar-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the Parquet file\n",
        "df = pd.read_parquet('./shopping_queries_dataset_examples.parquet')\n",
        "\n",
        "# Display the first few rows\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eVgHwyHU3vH",
        "outputId": "71158637-480e-4e6a-d7a9-1e38df86af46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   example_id           query  query_id  product_id product_locale esci_label  \\\n",
            "0           0   revent 80 cfm         0  B000MOO21W             us          I   \n",
            "1           1   revent 80 cfm         0  B07X3Y6B1V             us          E   \n",
            "2           2   revent 80 cfm         0  B07WDM7MQQ             us          E   \n",
            "3           3   revent 80 cfm         0  B07RH6Z8KW             us          E   \n",
            "4           4   revent 80 cfm         0  B07QJ7WYFQ             us          E   \n",
            "\n",
            "   small_version  large_version  split  \n",
            "0              0              1  train  \n",
            "1              0              1  train  \n",
            "2              0              1  train  \n",
            "3              0              1  train  \n",
            "4              0              1  train  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSUguyI1WRUI",
        "outputId": "77f10267-c4e6-4155-d678-391a07dd8359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['example_id', 'query', 'query_id', 'product_id', 'product_locale',\n",
            "       'esci_label', 'small_version', 'large_version', 'split'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "locale_us = df.loc[df['product_locale'] == 'us']\n",
        "unique_query = locale_us['query'].unique()\n",
        "\n",
        "FIELDS = ['query']\n",
        "\n",
        "csv_file = open('./query.csv', 'w+')\n",
        "writer = csv.DictWriter(csv_file, fieldnames=FIELDS)\n",
        "writer.writeheader()\n",
        "\n",
        "for q in unique_query:\n",
        "    writer.writerows([{'query': f'{unidecode(q)}'}])\n",
        "\n",
        "csv_file.close()"
      ],
      "metadata": {
        "id": "ldYw2nX4XdvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Write `init.sql` - don't use this"
      ],
      "metadata": {
        "id": "2HbFkjm9sFHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of records per category.\n",
        "NUM_RECORDS = 10_000\n",
        "\n",
        "# Constants\n",
        "SQL_INSERT = \"INSERT INTO public.\\\"Listings\\\" (seller_id, title, price, location, postal_code, status, category) VALUES\\n\"\n",
        "LOCATION = \"'POINT(48.378400 -123.415600)'::GEOMETRY\"\n",
        "POSTAL_CODE = \"'V8R6N2'\"\n",
        "STATUS = \"'AVAILABLE'\"\n",
        "\n",
        "# from https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023/tree/main/raw/meta_categories\n",
        "categories = [\n",
        "    'Appliances',\n",
        "    'Automotive',\n",
        "    'Beauty_and_Personal_Care',\n",
        "    'Cell_Phones_and_Accessories',\n",
        "    'Clothing_Shoes_and_Jewelry',\n",
        "    'Electronics',\n",
        "    'Health_and_Household',\n",
        "    'Home_and_Kitchen',\n",
        "    'Industrial_and_Scientific',\n",
        "    'Musical_Instruments',\n",
        "    'Office_Products',\n",
        "    'Patio_Lawn_and_Garden',\n",
        "    'Sports_and_Outdoors',\n",
        "    'Tools_and_Home_Improvement',\n",
        "    'Video_Games'\n",
        "]\n",
        "\n",
        "# Create new file - this will overwrite existing files.\n",
        "f = open('./insert.sql', 'w+')\n",
        "\n",
        "\n",
        "for category in categories:\n",
        "\n",
        "    # stream dataset\n",
        "    dataset = datasets.load_dataset(\n",
        "        \"McAuley-Lab/Amazon-Reviews-2023\",\n",
        "        f\"raw_meta_{category}\",\n",
        "        split=\"full\",\n",
        "        trust_remote_code=True,\n",
        "        streaming=True\n",
        "    )\n",
        "\n",
        "    # shuffle dataset and grab 100 items\n",
        "    # dataset = dataset.shuffle(seed=42, buffer_size=1_000)\n",
        "    dataset = dataset.take(NUM_RECORDS)\n",
        "\n",
        "    print(f\"Writing [{category}]...\\n\")\n",
        "\n",
        "    f.write(SQL_INSERT) # start with insert statement\n",
        "\n",
        "    for i, item in enumerate(dataset):\n",
        "        if all(x not in [item['title'], item['price'], item['main_category']] for x in ['None', None, '']):\n",
        "            line = f\"({(i%20) + 1}, $${unidecode(item['title'])}$$, {item['price']}, {LOCATION}, {POSTAL_CODE}, {STATUS}, '{item['main_category']}')\"\n",
        "\n",
        "            if i > 0:\n",
        "                f.write(',\\n' + line)\n",
        "            else:\n",
        "                f.write(line)\n",
        "\n",
        "    f.write(';\\n')\n",
        "\n",
        "    f.write('\\n\\n') # add new lines\n",
        "\n",
        "f.close()"
      ],
      "metadata": {
        "id": "Kg4SPfoGsETU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Write `data.csv` - use this instead"
      ],
      "metadata": {
        "id": "zDauBZSYsKWq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4VDIveLd4eq",
        "outputId": "fb229936-0c93-4302-b6db-50dfda8f9278"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing [Appliances]...\n",
            "\n",
            "Writing [Automotive]...\n",
            "\n",
            "Writing [Beauty_and_Personal_Care]...\n",
            "\n",
            "Writing [Cell_Phones_and_Accessories]...\n",
            "\n",
            "Writing [Clothing_Shoes_and_Jewelry]...\n",
            "\n",
            "Writing [Electronics]...\n",
            "\n",
            "Writing [Health_and_Household]...\n",
            "\n",
            "Writing [Home_and_Kitchen]...\n",
            "\n",
            "Writing [Industrial_and_Scientific]...\n",
            "\n",
            "Writing [Musical_Instruments]...\n",
            "\n",
            "Writing [Office_Products]...\n",
            "\n",
            "Writing [Patio_Lawn_and_Garden]...\n",
            "\n",
            "Writing [Sports_and_Outdoors]...\n",
            "\n",
            "Writing [Tools_and_Home_Improvement]...\n",
            "\n",
            "Writing [Video_Games]...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from random import randrange\n",
        "\n",
        "# Number of records per category.\n",
        "NUM_RECORDS = 20_000\n",
        "\n",
        "# Constants\n",
        "# SQL_INSERT = \"INSERT INTO public.\\\"Listings\\\" (seller_id, title, price, location, postal_code, status, listed_at, last_updated_at, category) VALUES\\n\"\n",
        "FIELDS = ['seller_id', 'title', 'price', 'latitude', 'longitude', 'postal_code', 'status', 'listed_at', 'last_updated_at', 'category']\n",
        "LATITUDE = 48.378400\n",
        "LONGITUDE = -123.415600\n",
        "POSTAL_CODE = 'V8R6N2'\n",
        "STATUS = 'AVAILABLE'\n",
        "TIMESTAMP=datetime.datetime(2024, 7, 1)\n",
        "\n",
        "\n",
        "\n",
        "# from https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023/tree/main/raw/meta_categories\n",
        "categories = [\n",
        "    'Appliances',\n",
        "    'Automotive',\n",
        "    'Beauty_and_Personal_Care',\n",
        "    'Cell_Phones_and_Accessories',\n",
        "    'Clothing_Shoes_and_Jewelry',\n",
        "    'Electronics',\n",
        "    'Health_and_Household',\n",
        "    'Home_and_Kitchen',\n",
        "    'Industrial_and_Scientific',\n",
        "    'Musical_Instruments',\n",
        "    'Office_Products',\n",
        "    'Patio_Lawn_and_Garden',\n",
        "    'Sports_and_Outdoors',\n",
        "    'Tools_and_Home_Improvement',\n",
        "    'Video_Games'\n",
        "]\n",
        "\n",
        "# Create csv file - this will overwrite existing files.\n",
        "csv_file = open('./listings.csv', 'w+')\n",
        "\n",
        "writer = csv.DictWriter(csv_file, fieldnames=FIELDS)\n",
        "writer.writeheader()\n",
        "\n",
        "for category in categories:\n",
        "\n",
        "    # stream dataset\n",
        "    dataset = datasets.load_dataset(\n",
        "        \"McAuley-Lab/Amazon-Reviews-2023\",\n",
        "        f\"raw_meta_{category}\",\n",
        "        split=\"full\",\n",
        "        trust_remote_code=True,\n",
        "        streaming=True\n",
        "    )\n",
        "\n",
        "    # shuffle dataset and grab 100 items\n",
        "    # dataset = dataset.shuffle(seed=42, buffer_size=1_000)\n",
        "    dataset = dataset.take(NUM_RECORDS)\n",
        "\n",
        "    print(f\"Writing [{category}]...\\n\")\n",
        "    for i, item in enumerate(dataset):\n",
        "        try:\n",
        "            float(item['price'])\n",
        "            if all(x not in [item['title'], item['price'], item['main_category']] for x in ['None', None, '']):\n",
        "                row = [{\n",
        "                    'seller_id': randrange(1, 4021),\n",
        "                    'title': unidecode(item['title']),\n",
        "                    'price': item['price'],\n",
        "                    'latitude': LATITUDE,\n",
        "                    'longitude': LONGITUDE,\n",
        "                    'postal_code': POSTAL_CODE,\n",
        "                    'status': STATUS,\n",
        "                    'listed_at': TIMESTAMP,\n",
        "                    'last_updated_at': TIMESTAMP,\n",
        "                    'category': item['main_category']\n",
        "                }]\n",
        "\n",
        "                writer.writerows(row)\n",
        "        except :\n",
        "            continue\n",
        "\n",
        "csv_file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download file"
      ],
      "metadata": {
        "id": "hdMSywQG7lQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "# files.download('insert.sql')\n",
        "# files.download('listings.csv')\n",
        "files.download('query.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "SI_ksEzqndIu",
        "outputId": "0e58ca09-f210-444b-d511-33b80638c623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f321421b-9418-4bd5-a618-cda0aa623b91\", \"query.csv\", 2256147)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}